{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27c2aa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Key developments involving Los Chapitos Gang in Mexico, February 2025  In\n",
      "February 2025, Los Chapitos Gang continued to pose a significant threat to\n",
      "security in Mexico, particularly in the state of Sinaloa. The gang, once a\n",
      "faction of the Sinaloa Cartel, became increasingly independent and violent in\n",
      "recent years.  The worst incidents occurred on February 17 in Culiacan Rosales,\n",
      "Sinaloa, where the clashes between Los Chapitos and Los Mayitos resulted in two\n",
      "fatalities (MEX\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "ACTOR_NAME = \"Los Chapitos Gang\"\n",
    "YEAR, MONTH = 2025, 2                    # February 2025\n",
    "MODEL  = \"HuggingFaceH4/zephyr-7b-beta\"  # free, open-access\n",
    "HF_TOKEN = \"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\"   # <-- keep safe!\n",
    "NEO_URI, NEO_USER, NEO_PWD = \"bolt://localhost:7687\", \"neo4j\", \"password\"\n",
    "MAX_EVENTS_IN_PROMPT = 12                # keep prompt concise\n",
    "\n",
    "# ============================================================\n",
    "# 1 · Fetch slice from Neo4j\n",
    "# ============================================================\n",
    "from neo4j import GraphDatabase, basic_auth\n",
    "import pandas as pd, textwrap, requests\n",
    "\n",
    "driver = GraphDatabase.driver(NEO_URI, auth=basic_auth(NEO_USER, NEO_PWD))\n",
    "cypher = \"\"\"\n",
    "MATCH (a:Actor {name:$actor})<-[:INVOLVES]-(e:Event)-[:IN_STATE]->(s:State),\n",
    "      (e)-[:TYPE]->(t:EventType)\n",
    "WHERE e.year=$yr AND e.month=$mo\n",
    "RETURN e.id AS id, toString(e.date) AS date,\n",
    "       s.admin1 AS state, t.code AS type,\n",
    "       e.fatalities AS fat, e.notes AS note\n",
    "ORDER BY fat DESC, date ASC\n",
    "\"\"\"\n",
    "with driver.session() as sess:\n",
    "    rows = sess.run(cypher, actor=ACTOR_NAME, yr=YEAR, mo=MONTH).data()\n",
    "driver.close()\n",
    "\n",
    "if not rows:\n",
    "    raise ValueError(\"No events found – check actor name or month.\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "tot_events, tot_fat, uniq_states = len(df), int(df.fat.sum()), df.state.nunique()\n",
    "\n",
    "core = (df.sort_values([\"fat\",\"date\"], ascending=[False, True])\n",
    "          .head(MAX_EVENTS_IN_PROMPT))\n",
    "\n",
    "bullets = \"\\n\".join(\n",
    "    f\"- ({r.id}) {r.date}, {r.state}: {r.type.lower()} – \"\n",
    "    f\"{r.fat} fat. {r.note[:120]}...\"\n",
    "    for r in core.itertuples()\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2 · Build LLM prompt\n",
    "# ============================================================\n",
    "prompt = f\"\"\"You are an analyst writing a conflict-early-warning brief.\n",
    "Summarise key developments involving *{ACTOR_NAME}* in Mexico, February 2025.\n",
    "\n",
    "Context\n",
    "-------\n",
    "Total events : {tot_events}\n",
    "Fatalities    : {tot_fat}\n",
    "States        : {uniq_states}\n",
    "\n",
    "Key events\n",
    "----------\n",
    "{bullets}\n",
    "\n",
    "Task\n",
    "----\n",
    "Write ≤80 words covering trends, worst incidents, affected states\n",
    "and notable tactics.  Cite Event IDs in parentheses.  Do **not** invent facts.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# 3 · Call Zephyr-7B (HF Inference-API)\n",
    "# ============================================================\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 120,\n",
    "        \"temperature\": 0.7,\n",
    "        \"return_full_text\": False\n",
    "    }\n",
    "}\n",
    "resp = requests.post(\n",
    "    f\"https://api-inference.huggingface.co/models/{MODEL}\",\n",
    "    headers=headers, json=payload, timeout=60\n",
    ")\n",
    "resp.raise_for_status()\n",
    "summary = resp.json()[0][\"generated_text\"].strip()\n",
    "\n",
    "# ============================================================\n",
    "# 4 · Output\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*72)\n",
    "print(textwrap.fill(summary, width=80))\n",
    "print(\"=\"*72)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
