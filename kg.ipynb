{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b421207",
   "metadata": {},
   "source": [
    "## 1. Get data from acled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be691d9",
   "metadata": {},
   "source": [
    "This script gets all acled data on mexico in 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e272a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 5000 rows\n",
      "Page 2: 2124 rows\n",
      "✅ Finished. CSV saved as acled_mexico_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import requests, csv, io, os\n",
    "\n",
    "API      = \"https://api.acleddata.com/acled/read.csv\"\n",
    "EMAIL    = \"hannes.schiemann@bse.eu\"\n",
    "API_KEY  = \"mMf1VD0-TEhEp34fg1VX\"\n",
    "COUNTRY  = \"Mexico\"\n",
    "YEAR     = 2025\n",
    "LIMIT    = 5000              # maximum allowed\n",
    "outfile  = f\"acled_{COUNTRY.lower()}_{YEAR}.csv\"\n",
    "\n",
    "first_page = True\n",
    "page       = 1\n",
    "\n",
    "with open(outfile, \"w\", newline='', encoding=\"utf-8\") as fh_out:\n",
    "    writer = None\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"email\": EMAIL,\n",
    "            \"key\"  : API_KEY,\n",
    "            \"country\": COUNTRY,\n",
    "            \"year\"   : YEAR,\n",
    "            \"limit\"  : LIMIT,\n",
    "            \"page\"   : page,\n",
    "        }\n",
    "        resp = requests.get(API, params=params, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        rows = list(csv.reader(io.StringIO(resp.text)))\n",
    "\n",
    "        if first_page:\n",
    "            writer = csv.writer(fh_out)\n",
    "            writer.writerows(rows)         # header + data\n",
    "            first_page = False\n",
    "        else:\n",
    "            writer.writerows(rows[1:])     # skip header on later pages\n",
    "\n",
    "        print(f\"Page {page}: {len(rows)-1} rows\")\n",
    "        if len(rows) < LIMIT + 1:          # header + < LIMIT → last page\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "print(f\"✅ Finished. CSV saved as {outfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f673b",
   "metadata": {},
   "source": [
    "## 2. Create Knowledge Graph in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ff094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\",\n",
    "                              auth=(\"neo4j\",\"password\"))\n",
    "with driver.session() as s:\n",
    "    s.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    for row in s.run(\"SHOW CONSTRAINTS\"):\n",
    "        s.run(f\"DROP CONSTRAINT {row['name']}\")\n",
    "print(\"Neo4j is now empty.\")\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9686ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading events: 100%|██████████| 14/14 [00:02<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  ACLED CSV  ➜  Neo4j loader  (Year–Month–Day hierarchy)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "CSV_FILE = \"acled_mexico_2025.csv\"\n",
    "BOLT_URI = \"bolt://localhost:7687\"\n",
    "USER, PWD = \"neo4j\", \"password\"\n",
    "BATCH     = 500\n",
    "\n",
    "# ---------- dataframe prep ----------------------------------\n",
    "df = pd.read_csv(CSV_FILE, low_memory=False)\n",
    "df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n",
    "df[\"year\"]  = df[\"event_date\"].dt.year.astype(int)\n",
    "df[\"month\"] = df[\"event_date\"].dt.month.astype(int)\n",
    "df[\"day\"]   = df[\"event_date\"].dt.day.astype(int)\n",
    "df[\"date_int\"] = df[\"event_date\"].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "\n",
    "def nz(v): return None if pd.isna(v) else str(v).strip()\n",
    "\n",
    "def to_dict(r):\n",
    "    return dict(\n",
    "        id         = r.event_id_cnty,\n",
    "        date_str   = r.event_date.strftime(\"%Y-%m-%d\"),\n",
    "        year       = int(r.year),\n",
    "        month      = int(r.month),\n",
    "        day        = int(r.day),\n",
    "        date_int   = int(r.date_int),\n",
    "        fatalities = 0 if pd.isna(r.fatalities) else int(r.fatalities),\n",
    "        notes      = nz(r.notes) or \"\",\n",
    "        admin1     = nz(r.admin1),\n",
    "        lat        = None if pd.isna(r.latitude)  else float(r.latitude),\n",
    "        lon        = None if pd.isna(r.longitude) else float(r.longitude),\n",
    "        etype      = nz(r.event_type),\n",
    "        actor1     = nz(r.actor1),\n",
    "        inter1     = nz(r.inter1),\n",
    "        actor2     = nz(r.actor2),\n",
    "        inter2     = nz(r.inter2)\n",
    "    )\n",
    "\n",
    "driver = GraphDatabase.driver(BOLT_URI, auth=(USER, PWD))\n",
    "with driver.session() as s:\n",
    "\n",
    "    # -- constraints -------------------------------------------------------\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (e:Event)      REQUIRE e.id IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (a:Actor)      REQUIRE a.name IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (g:ActorGroup) REQUIRE g.name IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (t:EventType)  REQUIRE t.code IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (s:State)      REQUIRE s.admin1 IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (y:Year)       REQUIRE y.value IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (m:Month) REQUIRE (m.year,m.value) IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (d:Day)   REQUIRE d.date_int IS UNIQUE\")\n",
    "\n",
    "    # -- static dimension nodes ------------------------------------------\n",
    "    for row in df[[\"admin1\",\"latitude\",\"longitude\"]].drop_duplicates().itertuples(False):\n",
    "        s.run(\"MERGE (st:State {admin1:$a}) \"\n",
    "              \"ON CREATE SET st.lat=$lat, st.lon=$lon\",\n",
    "              a=row.admin1, lat=row.latitude, lon=row.longitude)\n",
    "\n",
    "    for et in df[\"event_type\"].dropna().unique():\n",
    "        s.run(\"MERGE (:EventType {code:$c})\", c=et)\n",
    "\n",
    "    for grp in pd.unique(df[[\"inter1\",\"inter2\"]].values.ravel()):\n",
    "        if pd.notna(grp) and grp:\n",
    "            s.run(\"MERGE (:ActorGroup {name:$n})\", n=grp)\n",
    "\n",
    "    # -- batch insert -----------------------------------------------------\n",
    "    cypher = \"\"\"\n",
    "    UNWIND $rows AS row\n",
    "    // Time hierarchy -----------------------------------------------------\n",
    "    MERGE (y:Year  {value:row.year})\n",
    "    MERGE (m:Month {year:row.year, value:row.month})\n",
    "    MERGE (y)-[:HAS_MONTH]->(m)\n",
    "    MERGE (d:Day   {year:row.year, month:row.month, value:row.day, date_int:row.date_int})\n",
    "    MERGE (m)-[:HAS_DAY]->(d)\n",
    "\n",
    "    // Event --------------------------------------------------------------\n",
    "    MERGE (e:Event {id:row.id})\n",
    "      ON CREATE SET\n",
    "        e.date       = date(row.date_str),\n",
    "        e.year       = row.year,\n",
    "        e.month      = row.month,\n",
    "        e.day        = row.day,\n",
    "        e.date_int   = row.date_int,\n",
    "        e.fatalities = row.fatalities,\n",
    "        e.notes      = row.notes,\n",
    "        e.lat        = row.lat,\n",
    "        e.lon        = row.lon\n",
    "\n",
    "    // Link to time nodes\n",
    "    MERGE (e)-[:IN_YEAR ]->(y)\n",
    "    MERGE (e)-[:ON_MONTH]->(m)\n",
    "    MERGE (e)-[:ON_DAY  ]->(d)\n",
    "\n",
    "    WITH e, row                                         // separator #1\n",
    "\n",
    "    // Spatial ------------------------------------------------------------\n",
    "    MATCH (s:State {admin1:row.admin1})\n",
    "    MERGE (e)-[:IN_STATE]->(s)\n",
    "\n",
    "    WITH e, row                                         // separator #2\n",
    "\n",
    "    // EventType ----------------------------------------------------------\n",
    "    MATCH (t:EventType {code:row.etype})\n",
    "    MERGE (e)-[:TYPE]->(t)\n",
    "\n",
    "    WITH e, row                                         // separator #3\n",
    "\n",
    "    // Actors -------------------------------------------------------------\n",
    "    FOREACH (_ IN CASE WHEN row.actor1 IS NOT NULL THEN [1] ELSE [] END |\n",
    "      MERGE (a1:Actor {name:row.actor1})\n",
    "      MERGE (e)-[:INVOLVES {role:'actor1'}]->(a1)\n",
    "      FOREACH (_ IN CASE WHEN row.inter1 IS NOT NULL THEN [1] ELSE [] END |\n",
    "        MERGE (g1:ActorGroup {name:row.inter1})\n",
    "        MERGE (a1)-[:BELONGS_TO]->(g1)\n",
    "      )\n",
    "    )\n",
    "    FOREACH (_ IN CASE WHEN row.actor2 IS NOT NULL THEN [1] ELSE [] END |\n",
    "      MERGE (a2:Actor {name:row.actor2})\n",
    "      MERGE (e)-[:INVOLVES {role:'actor2'}]->(a2)\n",
    "      FOREACH (_ IN CASE WHEN row.inter2 IS NOT NULL THEN [1] ELSE [] END |\n",
    "        MERGE (g2:ActorGroup {name:row.inter2})\n",
    "        MERGE (a2)-[:BELONGS_TO]->(g2)\n",
    "      )\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    for start in tqdm(range(0, len(df), BATCH), desc=\"Loading events\"):\n",
    "        batch = [to_dict(r) for r in df.iloc[start:start+BATCH].itertuples()]\n",
    "        s.run(cypher, rows=batch)\n",
    "\n",
    "print(\"✅ Graph loaded successfully\")\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
